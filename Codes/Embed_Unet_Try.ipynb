{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbcc3124-4773-4f0e-b65d-f3fd42d51674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 480ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (128,128,3) into shape (128,4,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 88\u001b[0m\n\u001b[0;32m     86\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/lenovo/Documents/GitHub/Mechatronics/Paper Submission/Aerial Image2.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     87\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/lenovo/Documents/GitHub/Mechatronics/Codes/crop_row_detection_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 88\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 66\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(image_path, model_path)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(image_path, model_path):\n\u001b[0;32m     65\u001b[0m     detector \u001b[38;5;241m=\u001b[39m CropRowDetector(model_path)\n\u001b[1;32m---> 66\u001b[0m     original_image, reconstructed_image \u001b[38;5;241m=\u001b[39m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_full_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m original_image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m reconstructed_image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m         plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "Cell \u001b[1;32mIn[10], line 60\u001b[0m, in \u001b[0;36mCropRowDetector.process_full_image\u001b[1;34m(self, image_path)\u001b[0m\n\u001b[0;32m     57\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(predicted_mask)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Reconstruct the predicted image\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m reconstructed_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreconstruct_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img, reconstructed_image\n",
      "Cell \u001b[1;32mIn[10], line 38\u001b[0m, in \u001b[0;36mCropRowDetector.reconstruct_image\u001b[1;34m(self, predictions, original_shape, size)\u001b[0m\n\u001b[0;32m     36\u001b[0m             mask \u001b[38;5;241m=\u001b[39m predictions[index]\u001b[38;5;241m.\u001b[39msqueeze()  \u001b[38;5;66;03m# Remove any singleton dimensions\u001b[39;00m\n\u001b[0;32m     37\u001b[0m             mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([mask] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Convert (128, 128) to (128, 128, 3)\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m             reconstructed[y:y\u001b[38;5;241m+\u001b[39msize[\u001b[38;5;241m1\u001b[39m], x:x\u001b[38;5;241m+\u001b[39msize[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m mask\n\u001b[0;32m     39\u001b[0m             index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reconstructed\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (128,128,3) into shape (128,4,3)"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Constants\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "\n",
    "class CropRowDetector:\n",
    "    def __init__(self, model_path):\n",
    "        self.model = tf.keras.models.load_model(model_path, compile=False)\n",
    "\n",
    "    def preprocess_image(self, image):\n",
    "        img = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
    "        img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "        return img\n",
    "\n",
    "    def split_image(self, image, size=(IMG_WIDTH, IMG_HEIGHT)):\n",
    "        h, w, _ = image.shape\n",
    "        sub_images = []\n",
    "        for y in range(0, h, size[1]):\n",
    "            for x in range(0, w, size[0]):\n",
    "                sub_img = image[y:y+size[1], x:x+size[0]]\n",
    "                if sub_img.shape[0] == size[1] and sub_img.shape[1] == size[0]:\n",
    "                    sub_images.append(sub_img)\n",
    "        return sub_images\n",
    "\n",
    "    def reconstruct_image(self, predictions, original_shape, size=(IMG_WIDTH, IMG_HEIGHT)):\n",
    "        reconstructed = np.zeros((original_shape[0], original_shape[1], 3), dtype=np.uint8)  # 3 channels for RGB\n",
    "        index = 0\n",
    "        \n",
    "        for y in range(0, original_shape[0], size[1]):\n",
    "            for x in range(0, original_shape[1], size[0]):\n",
    "                if index < len(predictions):\n",
    "                    mask = predictions[index].squeeze()  # Remove any singleton dimensions\n",
    "                    mask = np.stack([mask] * 3, axis=-1)  # Convert (128, 128) to (128, 128, 3)\n",
    "                    reconstructed[y:y+size[1], x:x+size[0]] = mask\n",
    "                    index += 1\n",
    "        return reconstructed\n",
    "\n",
    "    def process_full_image(self, image_path):\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(f\"Error: Unable to read image at {image_path}\")\n",
    "            return None\n",
    "        \n",
    "        original_shape = img.shape\n",
    "        sub_images = self.split_image(img)\n",
    "\n",
    "        # Predict for each sub-image\n",
    "        predictions = []\n",
    "        for sub_img in sub_images:\n",
    "            input_image = self.preprocess_image(sub_img)\n",
    "            prediction = self.model.predict(input_image)[0]\n",
    "            predicted_mask = (prediction > 0.5).astype(np.uint8) * 255  # Make sure it's a binary mask\n",
    "            predictions.append(predicted_mask)\n",
    "\n",
    "        # Reconstruct the predicted image\n",
    "        reconstructed_image = self.reconstruct_image(predictions, original_shape)\n",
    "\n",
    "        return img, reconstructed_image\n",
    "\n",
    "def main(image_path, model_path):\n",
    "    detector = CropRowDetector(model_path)\n",
    "    original_image, reconstructed_image = detector.process_full_image(image_path)\n",
    "    \n",
    "    if original_image is not None and reconstructed_image is not None:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(\"Original Image\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(cv2.cvtColor(reconstructed_image, cv2.COLOR_BGR2RGB))  # Show in color\n",
    "        plt.title(\"Reconstructed Output\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Image processing failed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify the image path and the model path\n",
    "    image_path = \"C:/Users/lenovo/Documents/GitHub/Mechatronics/Paper Submission/Aerial Image2.png\"\n",
    "    model_path = \"C:/Users/lenovo/Documents/GitHub/Mechatronics/Codes/crop_row_detection_model.h5\"\n",
    "    main(image_path, model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9728b21c-061a-46b9-b5c4-73859f2373a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f7d5f0-c090-4155-ba34-8fb676cc0837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
